{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1 style=\"font-size:40px;\">Image Classification using CNNs</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the *fourth* lab for Deep Learning!\n",
    "\n",
    "In this lab an CNN network to classify RGB images. Image classification refers to classify classes from images. This labs the *dataset* consist of multiple images where each image have a target label for classification.\n",
    "\n",
    "Good luck!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import imageio\n",
    "import torchvision\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets define the ```path``` to the dataset. Make sure you explore the directories of the dataset and get familiar with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_img_dir = \"../data/FlyingObjectDataset_10K/training\"\n",
    "validation_img_dir = \"../data/FlyingObjectDataset_10K/validation\"\n",
    "testing_img_dir = \"../data/FlyingObjectDataset_10K/testing\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are also going to start using ```tensorboard```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/classification_1') #make sure to adapt this to your needs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please make sure to read the [doc](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html) to understand how to correctly plot your ```losses``` and ```metrics``` to tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok now that we have the path to the tree different splits, lets start by defining our ```Dataset``` class!\n",
    "The main two methods we need to define when subclassing ```Dataset``` is ```__getitem__``` and ```__len__```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlyingObjects(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset to Flying Object Dataset for the classification task.\n",
    "       The label information is encoded on the filename, __extract_label will extract the label following the chosen granularity\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, root,fine_grained=False,transform=None):\n",
    "        super(FlyingObjects,self).__init__()\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.fine_grained = fine_grained\n",
    "\n",
    "        self.images = [os.path.join(dp,f) for dp, dn, fn in os.walk(os.path.expanduser(self.root+'/image')) for f in fn if f.endswith(\".png\")]\n",
    "        self.images.sort()\n",
    "        \n",
    "        self.classes = [\n",
    "            'square_red',\n",
    "            'square_green',\n",
    "            'square_blue',\n",
    "            'square_yellow',\n",
    "            'triangle_red',\n",
    "            'triangle_green',\n",
    "            'triangle_blue',\n",
    "            'triangle_yellow',\n",
    "            'circular_red',\n",
    "            'circular_green',\n",
    "            'circular_blue',\n",
    "            'circular_yellow'\n",
    "        ] if self.fine_grained else [\n",
    "            'square',\n",
    "            'triangle',\n",
    "            'circular',\n",
    "            'background']\n",
    "        self.labels = [self.__extract_label(f) for f in self.images]\n",
    "    \n",
    "\n",
    "    def get_classes(self):\n",
    "        return self.classes\n",
    "    \n",
    "    \n",
    "    def __extract_label(self, image_file):\n",
    "        \"\"\"Extract label from image_file name\"\"\"\n",
    "        path, img_name = os.path.split(image_file)\n",
    "        names = img_name.split(\".\")[0].split(\"_\")\n",
    "\n",
    "        currLabel = names[1] + \"_\" + names[2] if self.fine_grained else names[1]\n",
    "\n",
    "        if currLabel in self.classes:\n",
    "            label = self.classes.index(currLabel)\n",
    "        else:\n",
    "            raise ValueError(\"ERROR: Label \" + str(currLabel) + \" is not defined!\")\n",
    "        return label\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # get data\n",
    "        x = imageio.imread(self.images[index])\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        else:\n",
    "            x = torch.from_numpy(x)\n",
    "        x = x.float()\n",
    "   \n",
    "        # get label\n",
    "        y = self.labels[index]\n",
    "        #y = np.eye(len(self.get_classes()))[y]\n",
    "        #y = torch.tensor(y)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define our transformations. Note that not all transformations are considered ```Data Augmentation```.\n",
    "The following transformations are used to convert our data to ```Tensor``` and resize our images to the desired size!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize((64, 64)), \n",
    "])\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize((64, 64))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Define the three dataloaders for the three splits: ```train```, ```validation``` and ```test```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not forget to visualize the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_with_labels(data, labels, title:str=None, nimages:int=10, nrows:int=2, fig_dimension=1,title_size=10, label_prefix=\"Label: \"):\n",
    "    \"\"\"Creates a grid of images with/without labels.\n",
    "\n",
    "    :param data: tensor\": B,W,H,C\n",
    "    :param labels: tensor\":  (Default value = None)\n",
    "    :param title: str:  (Default value = None)\n",
    "    :param nimages: int:  (Default value = 10)\n",
    "    :param nrows: int:  (Default value = 2)\n",
    "    :param fig_dimension: Default value = 1)\n",
    "    :param data:\"tensor\": \n",
    "    :param labels:\"tensor\":  (Default value = None)\n",
    "    :param title:str:  (Default value = None)\n",
    "    :param nimages:int:  (Default value = 10)\n",
    "    :param nrows:int:  (Default value = 2)\n",
    "\n",
    "    \"\"\"\n",
    "    image_ratio = data[0].shape[0] /data[0].shape[1]\n",
    "    if len(data)< nimages:\n",
    "        nimages = len(data)\n",
    " \n",
    "    columns = math.ceil(nimages/nrows)\n",
    "    \n",
    "    if nrows*columns > nimages:\n",
    "        nrows = math.ceil(nimages/columns)\n",
    "    \n",
    "    fig = plt.figure(figsize=(fig_dimension*columns,1.4*fig_dimension*nrows*image_ratio))\n",
    "    for i in range(0, nimages):\n",
    "        ax = fig.add_subplot(nrows, columns, i+1)\n",
    "        ax.imshow(data[i]/255)\n",
    "        ax.set_xlabel(f\"{label_prefix}{labels[i]}\") if labels is not None else None\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.grid(False)\n",
    "\n",
    "    if labels is None:\n",
    "        fig.suptitle(title,x=0.5, y=.95, size=title_size) \n",
    "        \n",
    "        fig.subplots_adjust(\n",
    "            left=0,\n",
    "            right=0.9,\n",
    "            top=0.9,\n",
    "            bottom=0,\n",
    "            wspace=0.1,\n",
    "            hspace=-0.45\n",
    "        )\n",
    "    else:\n",
    "        fig.suptitle(title) #,x=0.45, y=.95\n",
    "        \n",
    "        fig.subplots_adjust(\n",
    "            #left=0,\n",
    "            #right=1,\n",
    "            top=0.9,#+((nrows-1)*0.045),\n",
    "            #bottom=0,\n",
    "            wspace=0,\n",
    "            #hspace=0\n",
    "        )\n",
    "        \n",
    "    #plt.tight_layout(h_pad=0,w_pad=0)\n",
    "    fig.tight_layout(pad=0, h_pad=0,w_pad=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a very simple network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(torch.nn.Module):\n",
    "    def __init__(self,num_channels, num_classes, input_shape=(64,64)):\n",
    "        super(SimpleModel,self).__init__()\n",
    "        self.conv_layer1 = self._conv_layer_set(num_channels, 32)\n",
    "        self.conv_layer2 = self._conv_layer_set(32, 64)\n",
    "        self.fc1 = nn.Linear(64*input_shape[1]//4*input_shape[1]//4, 64) # Calculated with the size. why //4\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        \n",
    "    def _conv_layer_set(self, in_c, out_c):\n",
    "        conv_layer = nn.Sequential(OrderedDict([\n",
    "            ('conv',nn.Conv2d(in_c, out_c, kernel_size=3, padding=1)),\n",
    "            ('leakyrelu',nn.LeakyReLU()),\n",
    "            ('maxpool',nn.MaxPool2d(2)),\n",
    "        ]))\n",
    "        return conv_layer\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_layer1(x)\n",
    "        out = self.conv_layer2(out)\n",
    "       \n",
    "        out = out.view(out.size(0), -1)\n",
    "\n",
    "        out = self.fc1(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "Get inspired on the code you did on the previous lab and create your ```train function```. It might be useful to think about having a ```predict``` function too. Check the code of the previous lab if you need ideas!\n",
    "\n",
    "Do not forget, to train you need an ```optimizer```, ```loss function``` and an instance of your ```model```! If you need more inspiration check [here](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "Now that you have your train function. Train the network until it overfits. Which ```hyperparameters``` allowed you to overfit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help you visualize the results we provide a ```confusion matrix function```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix(loader,net,classes):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    # iterate over test data\n",
    "    for inputs, labels in loader:\n",
    "            output = net(inputs) # Feed Network\n",
    "\n",
    "            output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "            y_pred.extend(output) # Save Prediction\n",
    "\n",
    "            labels = labels.data.cpu().numpy()\n",
    "            y_true.extend(labels) # Save Truth\n",
    "            break\n",
    "\n",
    "    # Build confusion matrix\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cf_matrix,display_labels=classes)\n",
    "    disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "Go through the [doc](https://pytorch.org/vision/stable/transforms.html) about data augmentation transformations and use some in your pipeline. Did the ones you try improve your model? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "\n",
    "Redo the previous questions with an image size of ```128x128```. Make sure to note what changed and why. Compare both versions on ```Tensorboard``` plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "\n",
    "Once you have a good model for ```128x128``` without ```fine grain``` redo the experiments with ```fine grain```. How did the performance change? And why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
