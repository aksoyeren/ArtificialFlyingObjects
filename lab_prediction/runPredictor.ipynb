{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:40px;\"><center>Exercise IV:<br> Recurrent Neural Networks\n",
    "</center></h1>\n",
    "\n",
    "## Short summary\n",
    "In this exercise, we will design a recurrent network to predict future rgb images. These folder has **three files**: \n",
    "- **configPredictor.py:** this involves definitions of all parameters and data paths\n",
    "- **utilsPredictor.py:** includes utility functions required to grab and visualize data \n",
    "- **runPredictor.ipynb:** contains the script to design, train and test the network \n",
    "\n",
    "Make sure that before running this script, you created an environment and **installed all required libraries** such \n",
    "as keras.\n",
    "\n",
    "## The data\n",
    "There exists also a subfolder called **data** which contains the traning, validation, and testing data each has both RGB input images together with the corresponding ground truth images.\n",
    "\n",
    "\n",
    "## The exercises\n",
    "As for the previous lab all exercises are found below.\n",
    "\n",
    "\n",
    "## The different 'Cells'\n",
    "This notebook contains several cells with python code, together with the markdown cells (like this one) with only text. Each of the cells with python code has a \"header\" markdown cell with information about the code. The table below provides a short overview of the code cells. \n",
    "\n",
    "| #  |  CellName | CellType | Comment |\n",
    "| :--- | :-------- | :-------- | :------- |\n",
    "| 1 | Init | Needed | Sets up the environment|\n",
    "| 2 | Ex | Exercise 1| A class definition of a network model  |\n",
    "| 3 | Loading | Needed | Loading parameters and initializing the model |\n",
    "| 4 | Stats | Needed | Show data distribution | \n",
    "| 5 | Data | Needed | Generating the data batches |\n",
    "| 6 | Debug | Needed | Debugging the data |\n",
    "| 7 | Device | Needed | Selecting CPU/GPU |\n",
    "| 8 | Optimization | Exercise 2 | Selecting an optimization method |\n",
    "| 9 | Training | Exercise 1-2 | Training the model   |\n",
    "| 10 | Testing | Exercise 1-2| Testing the  method   | \n",
    "| 11 | Plotting | Information  | View some of test samples | \n",
    "\n",
    "\n",
    "In order for you to start with the exercise you need to run all cells. It is important that you do this in the correct order, starting from the top and continuing with the next cells. Later when you have started to work with the notebook it may be easier to use the command \"Run All\" found in the \"Cell\" dropdown menu.\n",
    "\n",
    "## Writing the report\n",
    "\n",
    "There is no need to provide any report. However, implemented network architecuture and observed experimental results must be presented as a short presentation in the last lecture, May 28."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) We first start with importing all required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from configPredictor import *\n",
    "cfg = flying_objects_config()\n",
    "if cfg.GPU >=0:\n",
    "    print(\"creating network model using gpu \" + str(cfg.GPU))\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(cfg.GPU)\n",
    "elif cfg.GPU >=-1:\n",
    "    print(\"creating network model using cpu \")  \n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from utilsPredictor import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import pprint\n",
    "\n",
    "# import the necessary packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv3D, Conv2D, Conv1D, Convolution2D, Deconvolution2D, Cropping2D, UpSampling2D\n",
    "from keras.layers import Input,  Conv2DTranspose, ConvLSTM2D, TimeDistributed\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D, Reshape, core, Dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Here, we have the network model class definition. In this class, the most important function is the one called **create_model()**. As defined in the exercises section, your task is to update the network architecture defined in this function such that the network will return the highest accuracy for the given training, validation, and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictorDNNModel():\n",
    "    def __init__(self, batch_size=32, inputShape=(64,64,3), dropout_prob=0.25): \n",
    "        self.batch_size = batch_size\n",
    "        self.inputShape = inputShape\n",
    "        self.dropout_prob = dropout_prob\n",
    " \n",
    "    def create_model(self):\n",
    "\n",
    "        inputs = Input(shape=self.inputShape) \n",
    "        down = ConvLSTM2D(filters=5, kernel_size=(1, 1),\n",
    "                       padding='same', return_sequences=True)(inputs) \n",
    "  \n",
    "        final = Conv3D(filters=3, kernel_size=(1, 1, 3),\n",
    "               activation='sigmoid', padding='same', data_format='channels_last')(down)\n",
    "  \n",
    "        model = Model(inputs=inputs, outputs=final)\n",
    "        model.summary()\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) We import the network **hyperparameters** and build a simple network by calling the class introduced in the previous step. Please note that to change the hyperparameters, you just need to change the values in the file called **configPredictor.py.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH, cfg.IMAGE_CHANNEL)\n",
    "input_shape = (int(cfg.SEQUENCE_LENGTH/2), cfg.IMAGE_HEIGHT, cfg.IMAGE_WIDTH, cfg.IMAGE_CHANNEL)\n",
    "modelObj = PredictorDNNModel(batch_size=cfg.BATCH_SIZE, inputShape=input_shape, dropout_prob=cfg.DROPOUT_PROB)\n",
    "model = modelObj.create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) We call the utility function **show_statistics** to display the data distribution. This is just for debugging purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### show how the data looks like\n",
    "show_statistics(cfg.training_data_dir, fineGrained=False, title=\" Training Data Statistics \")\n",
    "show_statistics(cfg.validation_data_dir, fineGrained=False, title=\" Validation Data Statistics \")\n",
    "show_statistics(cfg.testing_data_dir, fineGrained=False, title=\" Testing Data Statistics \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) We now create batch generators to get small batches from the entire dataset. There is no need to change these functions as they already return **normalized inputs as batches**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr_train_data = get_dataset_size(cfg.training_data_dir)\n",
    "nbr_valid_data = get_dataset_size(cfg.validation_data_dir)\n",
    "nbr_test_data = get_dataset_size(cfg.testing_data_dir)\n",
    "train_batch_generator = generate_futureframepredictor_batches(cfg.training_data_dir, image_shape, cfg.SEQUENCE_LENGTH, cfg.BATCH_SIZE)\n",
    "valid_batch_generator = generate_futureframepredictor_batches(cfg.validation_data_dir, image_shape, cfg.SEQUENCE_LENGTH, cfg.BATCH_SIZE)\n",
    "test_batch_generator = generate_futureframepredictor_batches(cfg.testing_data_dir, image_shape, cfg.SEQUENCE_LENGTH, cfg.BATCH_SIZE)\n",
    "print(\"Data batch generators are created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) We can visualize how the data looks like for debugging purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.DEBUG_MODE:\n",
    "    t_x, t_y = next(train_batch_generator)\n",
    "    print('train_x', t_x.shape, t_x.dtype, t_x.min(), t_x.max())\n",
    "    print('train_y', t_y.shape, t_y.dtype, t_y.min(), t_y.max()) \n",
    "    #plot_sample_futureframepredictor_data_with_groundtruth(t_x, t_y,t_y)\n",
    "    pprint.pprint (cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) We set the training configuration. As a part of the exercises, this function can also be updated to test different **optimization methods** such as **SGD, ADAM,** etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) We can now feed the training and validation data to the network. This will train the network for **some epochs**. Note that the epoch number is also predefined in the file called **configPredictor.py.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_log_dir = \"./logs/{}\".format(datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "model.fit_generator(generator = train_batch_generator,\n",
    "          epochs=cfg.NUM_EPOCHS,\n",
    "          verbose=1,\n",
    "          steps_per_epoch=(nbr_train_data//cfg.BATCH_SIZE), # total batch number\n",
    "          validation_steps=(nbr_valid_data // cfg.BATCH_SIZE), # total batch number\n",
    "          validation_data=valid_batch_generator,\n",
    "          callbacks=[TensorBoard(log_dir=output_log_dir, write_graph=True, write_images=False,\n",
    "                                 histogram_freq=0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) We can test the model with the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing model\n",
    "test_result = model.evaluate_generator(test_batch_generator,steps=(nbr_test_data//cfg.BATCH_SIZE))\n",
    "print('test_result', test_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) We can plot sample results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing sample results\n",
    "t_data, t_segments = next(test_batch_generator)\n",
    "pred_segments = model.predict(t_data, batch_size=cfg.BATCH_SIZE)\n",
    "plot_sample_futureframepredictor_data_with_groundtruth(t_data, t_segments, pred_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1)\n",
    "Update the network architecture given in the function **create_model** of the class PredictorDNNModel. Please note that the current image resolution is set to 32x32 (i.e. IMAGE_WIDTH and IMAGE_HEIGHT values) in the file configPredictor.py. \n",
    "This way initial experiements can run faster. Once you implement the inital version of the network, please set the resolution values back to 128x128. Experimental results should be provided for this high resolution images.  \n",
    "\n",
    "**Hint:** You can add more ConvLSTM layers etc. Batch normalization and dropout are other options to be considered. You can also try applying different activation functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2) \n",
    "Use different **optimization** (e.g. ADAM, SGD, etc) and **regularization** (e.g. data augmentation, dropout) methods to increase the network accuracy. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
